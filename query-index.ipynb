{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd33e94-cb04-463c-8d81-9a68a60f8cf4",
   "metadata": {},
   "source": [
    "# Query Index\n",
    "\n",
    "Once index has been created through indexing script, we can ask questions against it (a.k.a. querying). Querying also requires LLMs so this script also needs `OPENAI_API_KEY` (or equivalent for other LLMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9e79d-2ec0-4ce3-83bf-a4cf5461f46d",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c9e9105-82b6-4c7d-9c20-22bd3eb8b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set-up complete\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    # No creativity at all -- as in do not hallucinate. Be factually correct, always!\n",
    "    temperature = 0.0\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir = 'index')\n",
    "index = load_index_from_storage(storage_context)\n",
    "query_engine = index.as_query_engine(service_context=service_context)\n",
    "\n",
    "print('set-up complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ecf275-8bfe-4857-abea-0557d1fc80ef",
   "metadata": {},
   "source": [
    "## Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d4823f9-24b5-4e26-8e4d-1ddc81a7216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "...<question here>...\n",
    "\n",
    "Choose one of the options above.\n",
    "\n",
    "Cite your reference in form of \"page number: <page number>, text:'<text excerpt from the doc where answer was found>'\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba10f03c-d9f5-47f9-84c1-3997d124f2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't answer the question based on the given context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae715533-7d04-41b1-898d-ba4641f92e7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
